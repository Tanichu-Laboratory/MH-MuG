{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate MIDI base metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as ms21\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading ground truth: 100%|██████████| 2022/2022 [00:02<00:00, 730.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#-----set data (gt is npy files, pred is pt file)-----\n",
    "ground_truth_dir = \"/raid/koki-sakurai/model/dataset/data/npy/classical_jazz_1024_textcond/train\"\n",
    "ground_truth_pathes = glob.glob(ground_truth_dir + \"/*.npy\")\n",
    "prediction_path = \"/raid/koki-sakurai/model/train/pretrained/sample/finetuning-1600-100/sample_10_B.pt\"\n",
    "\n",
    "#-----load data-----\n",
    "ground_truths = []\n",
    "for path in tqdm(ground_truth_pathes, desc=\"loading ground truth\"):\n",
    "    ground_truth_tmp = np.load(path, allow_pickle=True).item()[\"midi\"]\n",
    "    ground_truths.append(ground_truth_tmp)\n",
    "predictions = torch.load(prediction_path, map_location=\"cpu\")[\"midi\"].detach().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(vector, note_split):\n",
    "    \"\"\"\n",
    "    midiに変換\n",
    "    \n",
    "    params\n",
    "    -------------\n",
    "    vector: numpy.ndarray\n",
    "        変換するmany-hot vector(チャンネル数, 長さ, 128)\n",
    "    note_split: int\n",
    "        分割する音符の種類\n",
    "    \n",
    "    returns\n",
    "    ---------\n",
    "    piano: object\n",
    "        midi_instrumentデータ\n",
    "    \"\"\"\n",
    "    vector = ((vector +1)*63.5).clip(0, 127)\n",
    "    #vector[vector >0.5] = 70\n",
    "    shapes = vector.shape\n",
    "    instrument_name = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "    piano = pretty_midi.Instrument(program=instrument_name)\n",
    "\n",
    "    #パラメータ\n",
    "    start_time = 0.0\n",
    "    end_time = 0.0\n",
    "    tempo = 120\n",
    "    time_split = 60/(tempo*note_split/4)\n",
    "\n",
    "    #ノートを追加\n",
    "    for p in range(shapes[-1]):\n",
    "        velocity = 0\n",
    "        start_time = 0.0\n",
    "        end_time = 0.0\n",
    "        durting = False #音が伸びているかどうか\n",
    "        on = 0 #音が鳴っているかどうか\n",
    "        for t in range(shapes[-2]):\n",
    "            if not durting:\n",
    "                on = int(round(vector[1][t][p]))\n",
    "                velocity = int(round(vector[0][t][p]))\n",
    "            end_time += time_split\n",
    "    \n",
    "            #次の時間において伸びているかの処理\n",
    "            if on > 0:\n",
    "                if t != shapes[-2]-1:\n",
    "                    sutain = int(round(vector[0][t+1][p]))\n",
    "                    if sutain > 0 and int(round(vector[1][t+1][p])) < 1:\n",
    "                        durting = True\n",
    "                        continue\n",
    "                    else:\n",
    "                        durting = False\n",
    "            else:\n",
    "                start_time = end_time\n",
    "                durting = False\n",
    "                continue      \n",
    "    \n",
    "            #add pitch\n",
    "            note = pretty_midi.Note(\n",
    "                velocity=velocity,\n",
    "                pitch=int(p),\n",
    "                start=start_time, \n",
    "                end=end_time\n",
    "            )\n",
    "            piano.notes.append(note)\n",
    "            start_time = end_time\n",
    "    \n",
    "    return piano\n",
    "\n",
    "def process_midi(path):\n",
    "    \"\"\"\n",
    "    process midi file to notes, bar, pattern, pattern_bar\n",
    "    \"\"\"\n",
    "    s=ms21.converter.parse(path)\n",
    "    note2id = {\n",
    "        \"C\": 0, \n",
    "        \"C#\": 1, \n",
    "        \"D\": 2, \n",
    "        \"E-\": 3, \n",
    "        \"E\": 4, \n",
    "        \"F\": 5, \n",
    "        \"F#\": 6, \n",
    "        \"G\": 7, \n",
    "        \"G#\": 8, \n",
    "        \"A\": 9, \n",
    "        \"B-\": 10,\n",
    "        \"B\": 11, \n",
    "    }\n",
    "\n",
    "    notes, bar, pattern, pattern_bar = [], [], [], [0 for k in range(16)]\n",
    "    lastoffset = 0\n",
    "    i, j = 1, 0\n",
    "    bar_step = 32 #1 bar per 4\n",
    "\n",
    "    for note in s.flat.notesAndRests:\n",
    "        if isinstance(note, ms21.note.Rest):\n",
    "            continue\n",
    "        #get notes perbar step\n",
    "        if note.offset >= bar_step * i and lastoffset < bar_step * i:\n",
    "            notes.append(bar)\n",
    "            bar = []\n",
    "            i += 1\n",
    "        #get pattern per bar\n",
    "        while note.offset >= 4 * (j + 1) and lastoffset < 4 * (j + 1):\n",
    "            pattern.append(np.array(pattern_bar))\n",
    "            pattern_bar = [0 for k in range(16)]\n",
    "            j += 1\n",
    "        #append bar and pattern with notes\n",
    "        if isinstance(note,ms21.note.Note):\n",
    "            # print(note.name, note.octave, note.pitch, note.pitch.midi, note.duration.quarterLength)\n",
    "            bar.append(note2id[note.name])\n",
    "            pattern_bar[int(4*(note.offset-4*j))] += 1\n",
    "        else:\n",
    "            try:\n",
    "                for c_note in note.notes:\n",
    "                    # print(c_note.name, c_note.pitch.midi, c_note.duration.quarterLength)\n",
    "                    bar.append(note2id[c_note.name])\n",
    "            except:\n",
    "                pass\n",
    "            pattern_bar[int(4*(note.offset-4*j))] += 1\n",
    "            \n",
    "        lastoffset = note.offset\n",
    "    \n",
    "    #append last bar step and bar\n",
    "    notes.append(bar)\n",
    "    pattern.append(np.array(pattern_bar))\n",
    "\n",
    "    return notes, bar, pattern, pattern_bar\n",
    "\n",
    "def get_features(melody):\n",
    "    \"\"\"\n",
    "    get features from melody\n",
    "    \n",
    "    params\n",
    "    -------------\n",
    "    melody: np.ndarray #melody data\n",
    "\n",
    "    returns\n",
    "    ---------\n",
    "    features: list #features\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for data in tqdm(melody, desc=\"get features\"):\n",
    "        #convert to midi\n",
    "        piano = convert_to_midi(data, 128)\n",
    "        midi = pretty_midi.PrettyMIDI()\n",
    "        midi.instruments.append(piano)\n",
    "        midi.write(\"tmp.mid\")\n",
    "        #process midi\n",
    "        notes, bar, pattern, pattern_bar = process_midi(\"tmp.mid\")\n",
    "        features.append([notes, bar, pattern, pattern_bar])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get ground truth features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get features:   0%|          | 0/2022 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/music21/stream/base.py:3694: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n",
      "get features: 100%|██████████| 2022/2022 [19:37<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#-----get ground truth features-----\n",
    "print(\"get ground truth features\")\n",
    "ground_truth_features = get_features(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get prediction features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get features: 100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#-----get prediction features-----\n",
    "print(\"get prediction features\")\n",
    "prediction_features = get_features(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate PCHE and GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCHE ground truth 2.9291662676669983\n",
      "GPS ground truth 0.6097825757877687\n",
      "PCHE prediction 2.844852203702743\n",
      "GPS prediction 0.5061830357142858\n"
     ]
    }
   ],
   "source": [
    "def pitch_class_histogram_entropy(notes):\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    for bar in notes:\n",
    "        # Construct the 12-dimensional pitch class histogram\n",
    "        histogram = np.zeros(12)\n",
    "        for note in bar:\n",
    "            pitch_class = note % 12\n",
    "            histogram[pitch_class] += 1\n",
    "\n",
    "        # Normalize the histogram\n",
    "        histogram = histogram / np.sum(histogram)\n",
    "\n",
    "        # Calculate the entropy\n",
    "        entropy = -np.sum(histogram * np.log2(histogram + 1e-6))  # Added epsilon to avoid log(0)\n",
    "        result.append(entropy)\n",
    "\n",
    "    return sum(result)/len(notes)\n",
    "\n",
    "def grooving_pattern_similarity(g_a, g_b):\n",
    "    assert len(g_a) == len(g_b), \"Grooving patterns must have the same length\"\n",
    "    Q = len(g_a)\n",
    "    gs = 1 - (1/Q) * np.sum(np.bitwise_xor(g_a, g_b))\n",
    "    return gs\n",
    "\n",
    "def cal_gps(pattern):\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(pattern)):\n",
    "        for j in range(i + 1, len(pattern)):\n",
    "            g_a, g_b = pattern[i], pattern[j]\n",
    "            results.append(grooving_pattern_similarity(g_a, g_b))\n",
    "\n",
    "    return sum(results) / len(results)\n",
    "\n",
    "#-----calculate PCHE and GPS-----\n",
    "pche_ground_truth = []\n",
    "gps_ground_truth = []\n",
    "pche_prediction = []\n",
    "gps_prediction = []\n",
    "\n",
    "for feature in ground_truth_features:\n",
    "    pche_ground_truth.append(pitch_class_histogram_entropy(feature[0]))\n",
    "    gps_ground_truth.append(cal_gps(feature[2]))\n",
    "\n",
    "for feature in prediction_features:\n",
    "    pche_prediction.append(pitch_class_histogram_entropy(feature[0]))\n",
    "    gps_prediction.append(cal_gps(feature[2]))\n",
    "\n",
    "#-----print result-----\n",
    "print(\"PCHE ground truth\", np.mean(pche_ground_truth))\n",
    "print(\"GPS ground truth\", np.mean(gps_ground_truth))\n",
    "print(\"PCHE prediction\", np.mean(pche_prediction))\n",
    "print(\"GPS prediction\", np.mean(gps_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
