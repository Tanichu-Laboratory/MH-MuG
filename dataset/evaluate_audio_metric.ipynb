{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate audio base metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as stats\n",
    "\n",
    "from audio_tools.scapeplot import (\n",
    "  compute_fitness_scape_plot,\n",
    "  normalization_properties_SSM\n",
    ")\n",
    "from audio_tools.ssm_features import (\n",
    "  compute_SM_from_filename,\n",
    "  compute_tempo_rel_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio_file_path):  \n",
    "    \"\"\"\n",
    "    Preprocess audio file to compute features and SM\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    audio_file_path : str #Path to audio file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    feature : np.array #Feature matrix\n",
    "    SM : np.array #Self-similarity matrix\n",
    "\n",
    "    \"\"\"\n",
    "    tempo_rel_set = compute_tempo_rel_set(0.5, 2, 7) # for tempo invariance\n",
    "    shift_set = np.array([x for x in range(12)])     # for tranposition invariance\n",
    "    rel_threshold = 0.25                             # the proportion of (highest) values to retain\n",
    "    penalty = -2                                     # all values below ``rel_threshold`` are set to this\n",
    "    _, _, feature, _, SM, _ = compute_SM_from_filename(\n",
    "        audio_file_path,\n",
    "        tempo_rel_set=tempo_rel_set, \n",
    "        shift_set=shift_set, \n",
    "        thresh=rel_threshold,\n",
    "        penalty=penalty\n",
    "    )\n",
    "    feature *= 10\n",
    "    return feature, SM\n",
    "\n",
    "def calculate_fitness(SM):\n",
    "    \"\"\"\n",
    "    Calculate fitness of a similarity matrix (SM) using the fitness scape plot.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    SM : np.ndarray #A similarity matrix.\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    fitness : float #The fitness of the similarity matrix.\n",
    "    \"\"\"\n",
    "    SSM = normalization_properties_SSM(SM)\n",
    "    fitness = compute_fitness_scape_plot(SSM)[0]\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing audio data:   0%|          | 0/2022 [00:00<?, ?it/s]/raid/koki-sakurai/model/dataset/audio_tools/ssm_features.py:347: FutureWarning: Pass sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  x, Fs = librosa.load(fn_wav, Fs)\n",
      "Preprocessing audio data:   0%|          | 1/2022 [00:01<36:25,  1.08s/it]/raid/koki-sakurai/model/dataset/audio_tools/ssm_features.py:347: FutureWarning: Pass sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  x, Fs = librosa.load(fn_wav, Fs)\n",
      "Preprocessing audio data: 100%|██████████| 2022/2022 [12:59<00:00,  2.59it/s]\n"
     ]
    }
   ],
   "source": [
    "#-----preprocess audio ground truth data------\n",
    "# get list of audio files\n",
    "audio_dir = \"data/audio/classical_jazz_1024/train\"\n",
    "audio_files = glob.glob(audio_dir + \"/*.wav\")\n",
    "#preprocess\n",
    "SMs_ground_truth = []\n",
    "features_ground_truth = [] #feature of the audio\n",
    "for audio_file in tqdm(audio_files, desc=\"Preprocessing audio data\"):\n",
    "    feature, SM = preprocess_audio(audio_file)\n",
    "    SMs_ground_truth.append(SM)\n",
    "    features_ground_truth.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing audio data: 100%|██████████| 100/100 [00:31<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#-----preprocess audio prediction data------\n",
    "# get list of audio files\n",
    "audio_dir = \"/raid/koki-sakurai/model/dataset/data/audio/samples/finetuning-1600-100/sample_10_B\"\n",
    "audio_files = glob.glob(audio_dir + \"/*.wav\")\n",
    "#preprocess\n",
    "SMs_presiction = []\n",
    "features_presiction = [] #feature of the audio\n",
    "for audio_file in tqdm(audio_files, desc=\"Preprocessing audio data\"):\n",
    "    feature, SM = preprocess_audio(audio_file)\n",
    "    SMs_presiction.append(SM)\n",
    "    features_presiction.append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diversity_ground_truth: 100%|██████████| 1011/1011 [00:00<00:00, 75010.90it/s]\n",
      "calculating diversity_prediction: 100%|██████████| 50/50 [00:00<00:00, 65027.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diversity_ground_truth:  5.586691833606032\n",
      "diversity_prediction:  4.983223407306591\n",
      "t:  3.029841582718565\n",
      "p:  0.002506190028094198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def cal_diversity(melody_A, melody_B):\n",
    "    \"\"\"\n",
    "    Calculate the diversity between two melodies\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    melody_A, melody_B: np.array\n",
    "    \"\"\"\n",
    "    #adjust the length of two melodies\n",
    "    if not melody_A.shape == melody_B.shape:\n",
    "        for dim in range(len(melody_A.shape)):\n",
    "            min_length = min(melody_A.shape[dim], melody_B.shape[dim])\n",
    "            if melody_A.shape[dim] > min_length:\n",
    "                for _ in range(melody_A.shape[dim] - min_length):\n",
    "                    melody_A = np.delete(melody_A, -1, axis=dim)\n",
    "            else:\n",
    "                for _ in range(melody_B.shape[dim] - min_length):\n",
    "                    melody_B = np.delete(melody_B, -1, axis=dim)\n",
    "\n",
    "    \n",
    "    return np.mean(np.abs(melody_A - melody_B)**2)\n",
    "\n",
    "#ground truth\n",
    "ground_truths = features_ground_truth\n",
    "ground_truths_A = ground_truths[:len(ground_truths)//2]\n",
    "ground_truths_B = ground_truths[len(ground_truths)//2:]\n",
    "#prediction\n",
    "predictions = features_presiction\n",
    "predictions_A = predictions[:len(predictions)//2]\n",
    "predictions_B = predictions[len(predictions)//2:]\n",
    "\n",
    "#------calculate diversity------\n",
    "diversities_ground_truth = []\n",
    "diversities_prediction = []\n",
    "#ground truth\n",
    "for idx in tqdm(range(len(ground_truths_A)), desc=\"calculating diversity_ground_truth\"):\n",
    "    diversity_ground_truth = cal_diversity(ground_truths_A[idx], ground_truths_B[idx])\n",
    "    diversities_ground_truth.append(diversity_ground_truth)\n",
    "#prediction\n",
    "for idx in tqdm(range(len(predictions_A)), desc=\"calculating diversity_prediction\"):\n",
    "    diversity_prediction = cal_diversity(predictions_A[idx], predictions_B[idx])\n",
    "    diversities_prediction.append(diversity_prediction)\n",
    "\n",
    "#------print result------\n",
    "print(\"diversity_ground_truth: \", np.mean(diversities_ground_truth))\n",
    "print(\"diversity_prediction: \", np.mean(diversities_prediction))\n",
    "\n",
    "#------t-test------\n",
    "t, p = stats.ttest_ind(diversities_ground_truth, diversities_prediction)\n",
    "print(\"t: \", t)\n",
    "print(\"p: \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating fitness of ground truth data: 100%|██████████| 2022/2022 [07:54<00:00,  4.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#-----calculate ground truth fitness------\n",
    "fitnesses_ground_truth = []\n",
    "for SM in tqdm(SMs_ground_truth, desc=\"Calculating fitness of ground truth data\"):\n",
    "    fitness = calculate_fitness(SM)\n",
    "    fitnesses_ground_truth.append(fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating fitness of prediction: 100%|██████████| 100/100 [00:23<00:00,  4.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#-----calculate prediction fitness------\n",
    "fitnesses_prediction = []\n",
    "for SM in tqdm(SMs_presiction, desc=\"Calculating fitness of prediction\"):\n",
    "    fitness = calculate_fitness(SM)\n",
    "    fitnesses_prediction.append(fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating SI of ground truth: 100%|██████████| 2022/2022 [00:00<00:00, 123406.76it/s]\n",
      "Calculating SI of prediction: 100%|██████████| 100/100 [00:00<00:00, 169947.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI_ground_truth 0.36214281988231506\n",
      "SI_prediction 0.34857934528497203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_SI(fitness):\n",
    "    \"\"\"\n",
    "    Calculate the SI of a fitness value.\n",
    "\n",
    "    params\n",
    "    ------\n",
    "    fitness : float #The fitness value.\n",
    "\n",
    "    return\n",
    "    ------\n",
    "    SI : float #The SI of the fitness value.\n",
    "    \"\"\"\n",
    "    return np.max(fitness)\n",
    "\n",
    "#-----calculate SI------\n",
    "SIs_ground_truth = []\n",
    "for fitness in tqdm(fitnesses_ground_truth, desc=\"Calculating SI of ground truth\"):\n",
    "    SI = calculate_SI(fitness)\n",
    "    SIs_ground_truth.append(SI)\n",
    "SIs_prediction = []\n",
    "for fitness in tqdm(fitnesses_prediction, desc=\"Calculating SI of prediction\"):\n",
    "    SI = calculate_SI(fitness)\n",
    "    SIs_prediction.append(SI)\n",
    "\n",
    "#-----print results------\n",
    "print(\"SI_ground_truth\", np.mean(SIs_ground_truth))\n",
    "print(\"SI_prediction\", np.mean(SIs_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
