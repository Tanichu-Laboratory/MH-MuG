#-------- detaset dir -------
dataset_dir_A: 
dataset_dir_B: 

#------ setting input data ------
data_length: 1024
input_names: ["midi"] #modalities of input data
input_shapes: #dims
  midi: [3, 1024, 128]

#------ train params ------
train_iteration: 50
checkpoint_interval: 10
batch_size: 64 #for getting text data
batch_size_diffusion: 32 #finetuning batch size of diffusion
batch_size_clip_probvlm: 256
learning_rate: 2e-5 #default: 2e-5
seed: 42
condition_type: text #condition type #text or class
use_clip_probvlm: True #flag of using text encoder

#------setting agent-------
mode: 1 #0: No communication, 1: all accept, other: MH
sampling_size: 100 #num of samples
finetuning_diffusion_itr: 1600 #finetuning iteration
finetuning_probvlm_itr: 100 #finetuning iteration
mh_model_path:
#A classical, B jazz
A:
  diffusion_path: 
  vae_path: 
  clip_path: 
  probvlm_path: 
B:
  diffusion_path: 
  vae_path: 
  clip_path: 
  probvlm_path: 

#------- setting using model -------
#support Diffusion
z_model: "Diffusion" #name of using model for obtain z
#support VAE
encoder: VAE #name of using model for encoder

#------- setting vae train mode -------
train_discriminator: False #default: False